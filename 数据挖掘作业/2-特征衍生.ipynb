{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征工程\n",
    "    IV值\n",
    "        全称是Information Value，中文意思是信息价值，或者信息量。假设在一个分类问题中，目标变量的类别有两类：Y1，Y2。对于一个待预测的个体A，要判断A属于Y1还是Y2，我们是需要一定的信息的，假设这个信息总量是I，而这些所需要的信息，就蕴含在所有的自变量C1，C2，C3，……，Cn中，那么，对于其中的一个变量Ci来说，其蕴含的信息越多，那么它对于判断A属于Y1还是Y2的贡献就越大，Ci的信息价值就越大，Ci的IV就越大，它就越应该进入到入模变量列表中。\n",
    "        计算：\n",
    "        IV的计算是以WOE（证据权重）为基础的。\n",
    "\n",
    "    \n",
    "    随机森林\n",
    "        随机森林是以决策树为基学习器的集成学习算法，在分类和回归上效果很好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV值方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalcIV(Xvar,Yvar):\n",
    "    N_0=np.sum(Yvar==0)\n",
    "    N_1=np.sum(Yvar==1)\n",
    "    N_0_group=np.zeros(np.unique(Xvar).shape)\n",
    "    \n",
    "    N_1_group=np.zeros(np.unique(Xvar).shape)\n",
    "    for i in range(len(np.unique(Xvar))):\n",
    "        N_0_group[i] = Yvar[(Xvar==np.unique(Xvar)[i])&(Yvar==0)].count()\n",
    "        N_1_group[i] = Yvar[(Xvar==np.unique(Xvar)[i])&(Yvar==1)].count()\n",
    "    iv = np.sum((N_0_group/N_0-N_1_group/N_1)*np.log((N_0_group/N_0)/(N_1_group/N_1)))\n",
    "    if iv>=1.0:## 处理极端值\n",
    "        iv=1\n",
    "    return iv\n",
    "\n",
    "def caliv_batch(df,Yvar):\n",
    "    ivlist=[]\n",
    "    for col in df.columns:\n",
    "        iv=CalcIV(df[col],Yvar)\n",
    "        ivlist.append(iv)\n",
    "    names=list(df.columns)\n",
    "    iv_df=pd.DataFrame({'Var':names,'Iv':ivlist},columns=['Var','Iv'])\n",
    "\n",
    "    return iv_df,ivlist\n",
    "im_iv, ivl = caliv_batch(datafinal,data_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#再数据处理：\n",
    "threshold = 0.02\n",
    "threshold2 = 0.6\n",
    "data_index=[]\n",
    "for i in range(len(ivl)):\n",
    "    if (im_iv['Iv'][i]< threshold)|(im_iv['Iv'][i] > threshold2):\n",
    "        data_index.append(im_iv['Var'][i])\n",
    "datafinal.drop(data_index,axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机森林："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "feat_lables = datafinal.columns\n",
    "forest = RandomForestClassifier(n_estimators=10000, random_state=0,n_jobs=1)\n",
    "forest.fit(datafinal, data_train)\n",
    "importance = forest.feature_importances_\n",
    "imp_result = np.argsort(importance)[::-1]\n",
    "\n",
    "for i in range(datafinal.shape[1]):\n",
    "    print(\"%2d. %-*s %f\"%(i+1, 30, feat_lables[i], importance[imp_result[i]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#筛选：\n",
    "threshold = 0.01\n",
    "data_index = list(datafinal.columns[ importance < threshold])\n",
    "datafinal.drop(data_index,axis=1,inplace=True)\n",
    "datafinal.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
