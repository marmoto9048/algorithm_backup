{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机森林算法梳理\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 集成学习的概念"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "构建并结合多个学习器来完成学习任务，也称为多分类器系统"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 个体学习器的概念\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "构成集成学习的学习器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### boosting bagging的概念、异同点\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### boosting：从原始样本集中使用Bootstraping 方法随机抽取n个训练样本，共进行k轮抽取，得到k个训练集（k个训练集之间相互独立，元素可以有重复）。\n",
    "对于n个训练集，我们训练k个模型，（这个模型可根据具体的情况而定，可以是决策树，knn等）\n",
    "\n",
    "bagging：对于训练集中的每个样本建立权值wi，表示对每个样本的权重， 其关键在与对于被错误分类的样本权重会在下一轮的分类中获得更大的权重（错误分类的样本的权重增加）。\n",
    "同时加大分类 误差概率小的弱分类器的权值，使其在表决中起到更大的作用，减小分类误差率较大弱分类器的权值，使其在表决中起到较小的作用。\n",
    "\n",
    "不同点：\n",
    "样本选择上: Bagging采取Bootstraping的是随机有放回的取样，Boosting的每一轮训练的样本是固定的，改变的是买个样的权重\n",
    "\n",
    "样本权重上：Bagging采取的是均匀取样，且每个样本的权重相同，Boosting根据错误率调整样本权重，错误率越大的样本权重会变大\n",
    "\n",
    "预测函数上：Bagging所以的预测函数权值相同，Boosting中误差越小的预测函数其权值越大。\n",
    "并行计算: Bagging 的各个预测函数可以并行生成;Boosting的各个预测函数必须按照顺序迭代生成."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 理解不同的结合策略(平均法，投票法，学习法)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "平均法：对于数值类的回归预测问题，通常使用的结合策略的平均法。对于很多个弱学习器输出得到的平均得到的最终预测输出进行分别给予权重\n",
    "\n",
    "投票法：把多个弱学习器的预测的结果组成一个集合，以少数服从多数的概念进行投票选择。\n",
    "\n",
    "学习法：对学习器作出两次学习，第一次学习后预测的结果作为第二次学习的输入，从而达到更精准的学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 随机森林的思想"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "为了解决单一决策树出现的很大误差，从而将多个决策树进行组合，解决单一决策树的片面性以及判断不准确。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 随机森林的推广"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "由于RF在实际应用中的良好特性，基于RF，有很多变种算法，应用也很广泛，不光可以用于分类回归，还可以用于特征转换，异常点检测等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 随机森林的优缺点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "优点\n",
    "具有极高的准确率\n",
    "随机性的引入，使得随机森林不容易过拟合\n",
    "随机性的引入，使得随机森林有很好的抗噪声能力\n",
    "能处理很高维度的数据，并且不用做特征选择\n",
    "既能处理离散型数据，也能处理连续型数据，数据集无需规范化\n",
    "训练速度快，可以得到变量重要性排序\n",
    "容易实现并行化\n",
    "\n",
    "缺点\n",
    "当随机森林中的决策树个数很多时，训练时需要的空间和时间会较大\n",
    "随机森林模型还有许多不好解释的地方，有点算个黑盒模型\n",
    "相比于其他算法，其输出预测可能较慢。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 随机森林在sklearn中的参数解释"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier(n_estimators=10,criterion=’gini’, max_depth=None,min_samples_split=2,min_samples_leaf=1,\n",
    "min_weight_fraction_leaf=0.0, max_features=’auto’, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=1, random_state=None,\n",
    "verbose=0, warm_start=False, class_weight=None)\n",
    "\n",
    "\n",
    "参数(params)：\n",
    "    n_estimators:数值型取值\n",
    "        含义：森林中决策树的个数，默认是10\n",
    "\n",
    "    criterion:字符型取值\n",
    "        含义：采用何种方法度量分裂质量，信息熵或者基尼指数，默认是基尼指数\n",
    "\n",
    "    max_features:取值为int型, float型, string类型, or None()，默认\"auto\"\n",
    "        含义：寻求最佳分割时的考虑的特征数量，即特征数达到多大时进行分割。\n",
    "        int:max_features等于这个int值\n",
    "        float:max_features是一个百分比，每(max_features * n_features)特征在每个分割出被考虑。\n",
    "        \"auto\":max_features等于sqrt(n_features)\n",
    "        \"sqrt\":同等于\"auto\"时\n",
    "        \"log2\":max_features=log2(n_features)\n",
    "        None:max_features = n_features\n",
    "\n",
    "    max_depth:int型取值或者None，默认为None\n",
    "        含义：树的最大深度\n",
    "\n",
    "    min_samples_split:int型取值，float型取值，默认为2\n",
    "        含义：分割内部节点所需的最少样本数量\n",
    "        int:如果是int值，则就是这个int值\n",
    "        float:如果是float值，则为min_samples_split * n_samples\n",
    "\n",
    "    min_samples_leaf:int取值，float取值，默认为1\n",
    "        含义：叶子节点上包含的样本最小值\n",
    "        int:就是这个int值\n",
    "        float:min_samples_leaf * n_samples\n",
    "\n",
    "    min_weight_fraction_leaf : float，default=0.\n",
    "        含义：能成为叶子节点的条件是：该节点对应的实例数和总样本数的比值，至少大于这个min_weight_fraction_leaf值\n",
    "\n",
    "    max_leaf_nodes:int类型，或者None(默认None)\n",
    "        含义：最大叶子节点数，以最好的优先方式生成树，最好的节点被定义为杂质相对较少，即纯度较高的叶子节点\n",
    "\n",
    "    min_impurity_split:float取值 \n",
    "        含义：树增长停止的阀值。一个节点将会分裂，如果他的杂质度比这个阀值；如果比这个值低，就会成为一个叶子节点。\n",
    "\n",
    "    min_impurity_decrease:float取值，默认0.\n",
    "        含义：一个节点将会被分裂，如果分裂之后，杂质度的减少效果高于这个值。\n",
    "\n",
    "    bootstrap:boolean类型取值，默认True\n",
    "        含义：是否采用有放回式的抽样方式\n",
    "\n",
    "    oob_score:boolean类型取值，默认False\n",
    "        含义：是否使用袋外样本来估计该模型大概的准确率\n",
    "\n",
    "    n_jobs:int类型取值，默认1\n",
    "        含义：拟合和预测过程中并行运用的作业数量。如果为-1，则作业数设置为处理器的core数。\n",
    "\n",
    "    class_weight:dict, list or dicts, \"balanced\"\n",
    "        含义：如果没有给定这个值，那么所有类别都应该是权重1\n",
    "        对于多分类问题，可以按照分类结果y的可能取值的顺序给出一个list或者dict值，用来指明各类的权重.\n",
    "        \"balanced\"模式，使用y值自动调整权重，该模式类别权重与输入数据中的类别频率成反比，\n",
    "即n_samples / (n_classes * np.bincount(y))，分布为第n个类别对应的实例数。\n",
    "        \"balanced_subsample\"模式和\"balanced\"模式类似，只是它计算使用的是有放回式的取样中取得样本数，而不是总样本数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 随机森林的应用场景"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为不需要很多参数调整就可以达到不错的效果，基本上不知道用什么方法的时候都可以先试一下随机森林。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
